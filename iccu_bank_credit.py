# -*- coding: utf-8 -*-
"""iccu_bank_credit.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qnH2La4WpsfikupNg2id_eUwTy1ijyff
"""

import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
import joblib

# Load and preprocess the data (same as before)
data_file_path = 'crx.data'
credit_data = pd.read_csv(data_file_path, header=None)
column_names = [
    'Gender', 'Age', 'Debt', 'Marital_Status', 'Bank_Customer', 'Education_Level',
    'Ethnicity', 'Years_Employed', 'Prior_Default', 'Employed', 'Credit_Score',
    'Drivers_License', 'Citizen', 'Zip_Code', 'Income', 'Approval_Status'
]
credit_data.columns = column_names

# Encode the target variable and categorical features
credit_data['Approval_Status'] = credit_data['Approval_Status'].map({'+': 1, '-': 0})
categorical_columns = credit_data.select_dtypes(include=['object']).columns.tolist()
credit_data_encoded = pd.get_dummies(credit_data, columns=categorical_columns, drop_first=True)

# Separate features and target variable
X = credit_data_encoded.drop('Approval_Status', axis=1)
y = credit_data_encoded['Approval_Status']

# Standardize the numerical features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y, test_size=0.2, random_state=42)

# Train the Random Forest model
random_forest = RandomForestClassifier(random_state=42)
random_forest.fit(X_train, y_train)

# Save the model to a file
joblib.dump(random_forest, 'random_forest_model.pkl')